INFO Executor task launch worker-1 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.463166 ms
DEBUG Executor task launch worker-1 org.apache.spark.storage.BlockManager - Getting local block broadcast_4
DEBUG Executor task launch worker-1 org.apache.spark.storage.BlockManager - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
DEBUG Executor task launch worker-0 org.apache.spark.storage.BlockManager - Getting local block broadcast_4
DEBUG Executor task launch worker-0 org.apache.spark.storage.BlockManager - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
INFO Executor task launch worker-1 org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 3). 2004 bytes result sent to driver
DEBUG dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_2, runningTasks: 1
DEBUG dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - No tasks for locality level NO_PREF, so moving to locality level ANY
INFO task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 3) in 2439 ms on localhost (1/2)
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapTask finished on driver
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - submitStage(ResultStage 3)
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - missing: List(ShuffleMapStage 2)
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - submitStage(ShuffleMapStage 2)
INFO Executor task launch worker-0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2004 bytes result sent to driver
DEBUG dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_2, runningTasks: 0
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 2569 ms on localhost (2/2)
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapTask finished on driver
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 2 (show at PQDataMLLib.scala:30) finished in 2.569 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
DEBUG dag-scheduler-event-loop org.apache.spark.MapOutputTrackerMaster - Increasing epoch to 1
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - submitStage(ResultStage 3)
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - missing: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at show at PQDataMLLib.scala:30), which has no missing parents
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - submitMissingTasks(ResultStage 3)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 17.1 KB, free 912.1 MB)
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManager - Put block broadcast_6 locally took  1 ms
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManager - Putting block broadcast_6 without replication took  1 ms
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.9 KB, free 912.1 MB)
INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on 192.168.1.200:64026 (size: 8.9 KB, free: 912.3 MB)
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_6_piece0
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManager - Told master about block broadcast_6_piece0
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManager - Put block broadcast_6_piece0 locally took  1 ms
DEBUG dag-scheduler-event-loop org.apache.spark.storage.BlockManager - Putting block broadcast_6_piece0 without replication took  2 ms
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at show at PQDataMLLib.scala:30)
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - New pending partitions: Set(0)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.TaskSetManager - Epoch for TaskSet 3.0: 1
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.TaskSetManager - Valid locality levels for TaskSet 3.0: ANY
DEBUG dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_3, runningTasks: 0
INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, ANY, 5190 bytes)
INFO Executor task launch worker-0 org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 4)
DEBUG Executor task launch worker-0 org.apache.spark.executor.Executor - Task 4's epoch is 1
DEBUG Executor task launch worker-0 org.apache.spark.storage.BlockManager - Getting local block broadcast_6
DEBUG Executor task launch worker-0 org.apache.spark.storage.BlockManager - Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
DEBUG Executor task launch worker-0 org.apache.spark.MapOutputTrackerMaster - Fetching outputs for shuffle 0, partitions 0-1
DEBUG Executor task launch worker-0 org.apache.spark.storage.ShuffleBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
INFO Executor task launch worker-0 org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
INFO Executor task launch worker-0 org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
DEBUG Executor task launch worker-0 org.apache.spark.storage.ShuffleBlockFetcherIterator - Got local blocks in  13 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateOrdering - Generated Ordering by input[0, string, true] ASC:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */
/* 011 */   public SpecificOrdering(Object[] references) {
/* 012 */     this.references = references;
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public int compare(InternalRow a, InternalRow b) {
/* 017 */     InternalRow i = null;  // Holds current row being evaluated.
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA;
/* 021 */     UTF8String primitiveA;
/* 022 */     {
/* 023 */
/* 024 */       boolean isNull = i.isNullAt(0);
/* 025 */       UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 026 */       isNullA = isNull;
/* 027 */       primitiveA = value;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB;
/* 031 */     UTF8String primitiveB;
/* 032 */     {
/* 033 */
/* 034 */       boolean isNull = i.isNullAt(0);
/* 035 */       UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 036 */       isNullB = isNull;
/* 037 */       primitiveB = value;
/* 038 */     }
/* 039 */     if (isNullA && isNullB) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = primitiveA.compare(primitiveB);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */     return 0;
/* 053 */   }
/* 054 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */
/* 011 */   public SpecificOrdering(Object[] references) {
/* 012 */     this.references = references;
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public int compare(InternalRow a, InternalRow b) {
/* 017 */     InternalRow i = null;  // Holds current row being evaluated.
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA;
/* 021 */     UTF8String primitiveA;
/* 022 */     {
/* 023 */
/* 024 */       boolean isNull = i.isNullAt(0);
/* 025 */       UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 026 */       isNullA = isNull;
/* 027 */       primitiveA = value;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB;
/* 031 */     UTF8String primitiveB;
/* 032 */     {
/* 033 */
/* 034 */       boolean isNull = i.isNullAt(0);
/* 035 */       UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 036 */       isNullB = isNull;
/* 037 */       primitiveB = value;
/* 038 */     }
/* 039 */     if (isNullA && isNullB) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = primitiveA.compare(primitiveB);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */     return 0;
/* 053 */   }
/* 054 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 36.708204 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection - code for sortprefix(input[0, string, true] ASC):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(1);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 0);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 1);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     rowWriter.zeroOutNullBytes();
/* 027 */
/* 028 */
/* 029 */     boolean isNull1 = i.isNullAt(0);
/* 030 */     UTF8String value1 = isNull1 ? null : (i.getUTF8String(0));
/* 031 */     long value = 0L;
/* 032 */     boolean isNull = false;
/* 033 */     if (!isNull1) {
/* 034 */       value = value1.getPrefix();
/* 035 */     }
/* 036 */     if (isNull) {
/* 037 */       rowWriter.setNullAt(0);
/* 038 */     } else {
/* 039 */       rowWriter.write(0, value);
/* 040 */     }
/* 041 */     return result;
/* 042 */   }
/* 043 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(1);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 0);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 1);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     rowWriter.zeroOutNullBytes();
/* 027 */
/* 028 */
/* 029 */     boolean isNull1 = i.isNullAt(0);
/* 030 */     UTF8String value1 = isNull1 ? null : (i.getUTF8String(0));
/* 031 */     long value = 0L;
/* 032 */     boolean isNull = false;
/* 033 */     if (!isNull1) {
/* 034 */       value = value1.getPrefix();
/* 035 */     }
/* 036 */     if (isNull) {
/* 037 */       rowWriter.setNullAt(0);
/* 038 */     } else {
/* 039 */       rowWriter.write(0, value);
/* 040 */     }
/* 041 */     return result;
/* 042 */   }
/* 043 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 128.512418 ms
DEBUG Executor task launch worker-0 org.apache.spark.memory.TaskMemoryManager - Task 4 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@345355e9
DEBUG Executor task launch worker-0 org.apache.spark.memory.TaskMemoryManager - Task 4 acquired 16.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@345355e9
DEBUG Executor task launch worker-0 org.apache.spark.sql.execution.aggregate.SortAggregateExec - Creating MutableProj: WrappedArray(), inputSchema: List()
DEBUG Spark Context Cleaner org.apache.spark.ContextCleaner - Got cleaning task CleanBroadcast(5)
DEBUG Spark Context Cleaner org.apache.spark.ContextCleaner - Cleaning broadcast 5
DEBUG Spark Context Cleaner org.apache.spark.broadcast.TorrentBroadcast - Unpersisting TorrentBroadcast 5
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManagerSlaveEndpoint - removing broadcast 5
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManager - Removing broadcast 5
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManager - Removing block broadcast_5
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 of size 9448 dropped from memory (free 939590822)
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManager - Removing block broadcast_5_piece0
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 of size 5207 dropped from memory (free 939596029)
INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on 192.168.1.200:64026 in memory (size: 5.1 KB, free: 912.3 MB)
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_5_piece0
DEBUG block-manager-slave-async-thread-pool-0 org.apache.spark.storage.BlockManager - Told master about block broadcast_5_piece0
DEBUG block-manager-slave-async-thread-pool-2 org.apache.spark.storage.BlockManagerSlaveEndpoint - Done removing broadcast 5, response is 0
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificMutableProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificMutableProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificMutableProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = new org.apache.spark.sql.catalyst.expressions.GenericMutableRow(0);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection target(MutableRow row) {
/* 019 */     mutableRow = row;
/* 020 */     return this;
/* 021 */   }
/* 022 */
/* 023 */   /* Provide immutable access to the last projected row. */
/* 024 */   public InternalRow currentValue() {
/* 025 */     return (InternalRow) mutableRow;
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */
/* 032 */     // copy all the results into MutableRow
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */ }

DEBUG Spark Context Cleaner org.apache.spark.ContextCleaner - Cleaned broadcast 5
DEBUG block-manager-slave-async-thread-pool-2 org.apache.spark.storage.BlockManagerSlaveEndpoint - Sent response: 0 to 192.168.1.200:64025
DEBUG Spark Context Cleaner org.apache.spark.ContextCleaner - Got cleaning task CleanAccum(88)
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificMutableProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificMutableProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificMutableProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = new org.apache.spark.sql.catalyst.expressions.GenericMutableRow(0);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection target(MutableRow row) {
/* 019 */     mutableRow = row;
/* 020 */     return this;
/* 021 */   }
/* 022 */
/* 023 */   /* Provide immutable access to the last projected row. */
/* 024 */   public InternalRow currentValue() {
/* 025 */     return (InternalRow) mutableRow;
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */
/* 032 */     // copy all the results into MutableRow
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */ }

DEBUG Spark Context Cleaner org.apache.spark.ContextCleaner - Cleaning accumulator 88
INFO Spark Context Cleaner org.apache.spark.ContextCleaner - Cleaned accumulator 88
INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 27.770245 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.execution.aggregate.SortAggregateExec - Creating MutableProj: ArrayBuffer(), inputSchema: ArrayBuffer(quote_id#0, L1_PROD_NAME#8, L2_PROD_NAME#9)
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificMutableProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificMutableProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificMutableProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = new org.apache.spark.sql.catalyst.expressions.GenericMutableRow(0);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection target(MutableRow row) {
/* 019 */     mutableRow = row;
/* 020 */     return this;
/* 021 */   }
/* 022 */
/* 023 */   /* Provide immutable access to the last projected row. */
/* 024 */   public InternalRow currentValue() {
/* 025 */     return (InternalRow) mutableRow;
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */
/* 032 */     // copy all the results into MutableRow
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(1);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 32);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 1);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     holder.reset();
/* 027 */
/* 028 */     rowWriter.zeroOutNullBytes();
/* 029 */
/* 030 */
/* 031 */     boolean isNull = i.isNullAt(0);
/* 032 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 033 */     if (isNull) {
/* 034 */       rowWriter.setNullAt(0);
/* 035 */     } else {
/* 036 */       rowWriter.write(0, value);
/* 037 */     }
/* 038 */     result.setTotalSize(holder.totalSize());
/* 039 */     return result;
/* 040 */   }
/* 041 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(1);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 32);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 1);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     holder.reset();
/* 027 */
/* 028 */     rowWriter.zeroOutNullBytes();
/* 029 */
/* 030 */
/* 031 */     boolean isNull = i.isNullAt(0);
/* 032 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 033 */     if (isNull) {
/* 034 */       rowWriter.setNullAt(0);
/* 035 */     } else {
/* 036 */       rowWriter.write(0, value);
/* 037 */     }
/* 038 */     result.setTotalSize(holder.totalSize());
/* 039 */     return result;
/* 040 */   }
/* 041 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.602683 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.execution.aggregate.SortAggregateExec - Creating MutableProj: WrappedArray(noop$(), noop$()), inputSchema: WrappedArray()
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection - code for noop$(),noop$():
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificMutableProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificMutableProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificMutableProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = new org.apache.spark.sql.catalyst.expressions.GenericMutableRow(2);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection target(MutableRow row) {
/* 019 */     mutableRow = row;
/* 020 */     return this;
/* 021 */   }
/* 022 */
/* 023 */   /* Provide immutable access to the last projected row. */
/* 024 */   public InternalRow currentValue() {
/* 025 */     return (InternalRow) mutableRow;
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */
/* 032 */     // copy all the results into MutableRow
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificMutableProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificMutableProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificMutableProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = new org.apache.spark.sql.catalyst.expressions.GenericMutableRow(2);
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public org.apache.spark.sql.catalyst.expressions.codegen.BaseMutableProjection target(MutableRow row) {
/* 019 */     mutableRow = row;
/* 020 */     return this;
/* 021 */   }
/* 022 */
/* 023 */   /* Provide immutable access to the last projected row. */
/* 024 */   public InternalRow currentValue() {
/* 025 */     return (InternalRow) mutableRow;
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */
/* 032 */     // copy all the results into MutableRow
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.23654 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer - 
=== Result of Batch CleanExpressions ===
!input[1, array<string>, true] AS PR2#39   input[1, array<string>, true]
!+- input[1, array<string>, true]          
        
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer - 
=== Result of Batch CleanExpressions ===
!input[2, array<string>, true] AS PR1#41   input[2, array<string>, true]
!+- input[2, array<string>, true]          
        
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection - code for input[0, string, true],input[1, array<string>, true],input[2, array<string>, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter arrayWriter;
/* 012 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter arrayWriter1;
/* 013 */
/* 014 */
/* 015 */   public SpecificUnsafeProjection(Object[] references) {
/* 016 */     this.references = references;
/* 017 */     result = new UnsafeRow(3);
/* 018 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 96);
/* 019 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 3);
/* 020 */     this.arrayWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter();
/* 021 */     this.arrayWriter1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter();
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     holder.reset();
/* 031 */
/* 032 */     rowWriter.zeroOutNullBytes();
/* 033 */
/* 034 */
/* 035 */     boolean isNull = i.isNullAt(0);
/* 036 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 037 */     if (isNull) {
/* 038 */       rowWriter.setNullAt(0);
/* 039 */     } else {
/* 040 */       rowWriter.write(0, value);
/* 041 */     }
/* 042 */
/* 043 */
/* 044 */     boolean isNull1 = i.isNullAt(1);
/* 045 */     ArrayData value1 = isNull1 ? null : (i.getArray(1));
/* 046 */     if (isNull1) {
/* 047 */       rowWriter.setNullAt(1);
/* 048 */     } else {
/* 049 */       // Remember the current cursor so that we can calculate how many bytes are
/* 050 */       // written later.
/* 051 */       final int tmpCursor1 = holder.cursor;
/* 052 */
/* 053 */       if (value1 instanceof UnsafeArrayData) {
/* 054 */
/* 055 */         final int sizeInBytes = ((UnsafeArrayData) value1).getSizeInBytes();
/* 056 */         // grow the global buffer before writing data.
/* 057 */         holder.grow(sizeInBytes);
/* 058 */         ((UnsafeArrayData) value1).writeToMemory(holder.buffer, holder.cursor);
/* 059 */         holder.cursor += sizeInBytes;
/* 060 */
/* 061 */       } else {
/* 062 */         final int numElements = value1.numElements();
/* 063 */         arrayWriter.initialize(holder, numElements, 0);
/* 064 */
/* 065 */         for (int index = 0; index < numElements; index++) {
/* 066 */           if (value1.isNullAt(index)) {
/* 067 */             arrayWriter.setNullAt(index);
/* 068 */           } else {
/* 069 */             final UTF8String element = value1.getUTF8String(index);
/* 070 */             arrayWriter.write(index, element);
/* 071 */           }
/* 072 */         }
/* 073 */       }
/* 074 */
/* 075 */       rowWriter.setOffsetAndSize(1, tmpCursor1, holder.cursor - tmpCursor1);
/* 076 */       rowWriter.alignToWords(holder.cursor - tmpCursor1);
/* 077 */     }
/* 078 */
/* 079 */
/* 080 */     boolean isNull2 = i.isNullAt(2);
/* 081 */     ArrayData value2 = isNull2 ? null : (i.getArray(2));
/* 082 */     if (isNull2) {
/* 083 */       rowWriter.setNullAt(2);
/* 084 */     } else {
/* 085 */       // Remember the current cursor so that we can calculate how many bytes are
/* 086 */       // written later.
/* 087 */       final int tmpCursor2 = holder.cursor;
/* 088 */
/* 089 */       if (value2 instanceof UnsafeArrayData) {
/* 090 */
/* 091 */         final int sizeInBytes1 = ((UnsafeArrayData) value2).getSizeInBytes();
/* 092 */         // grow the global buffer before writing data.
/* 093 */         holder.grow(sizeInBytes1);
/* 094 */         ((UnsafeArrayData) value2).writeToMemory(holder.buffer, holder.cursor);
/* 095 */         holder.cursor += sizeInBytes1;
/* 096 */
/* 097 */       } else {
/* 098 */         final int numElements1 = value2.numElements();
/* 099 */         arrayWriter1.initialize(holder, numElements1, 0);
/* 100 */
/* 101 */         for (int index1 = 0; index1 < numElements1; index1++) {
/* 102 */           if (value2.isNullAt(index1)) {
/* 103 */             arrayWriter1.setNullAt(index1);
/* 104 */           } else {
/* 105 */             final UTF8String element1 = value2.getUTF8String(index1);
/* 106 */             arrayWriter1.write(index1, element1);
/* 107 */           }
/* 108 */         }
/* 109 */       }
/* 110 */
/* 111 */       rowWriter.setOffsetAndSize(2, tmpCursor2, holder.cursor - tmpCursor2);
/* 112 */       rowWriter.alignToWords(holder.cursor - tmpCursor2);
/* 113 */     }
/* 114 */     result.setTotalSize(holder.totalSize());
/* 115 */     return result;
/* 116 */   }
/* 117 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter arrayWriter;
/* 012 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter arrayWriter1;
/* 013 */
/* 014 */
/* 015 */   public SpecificUnsafeProjection(Object[] references) {
/* 016 */     this.references = references;
/* 017 */     result = new UnsafeRow(3);
/* 018 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 96);
/* 019 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 3);
/* 020 */     this.arrayWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter();
/* 021 */     this.arrayWriter1 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeArrayWriter();
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     holder.reset();
/* 031 */
/* 032 */     rowWriter.zeroOutNullBytes();
/* 033 */
/* 034 */
/* 035 */     boolean isNull = i.isNullAt(0);
/* 036 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 037 */     if (isNull) {
/* 038 */       rowWriter.setNullAt(0);
/* 039 */     } else {
/* 040 */       rowWriter.write(0, value);
/* 041 */     }
/* 042 */
/* 043 */
/* 044 */     boolean isNull1 = i.isNullAt(1);
/* 045 */     ArrayData value1 = isNull1 ? null : (i.getArray(1));
/* 046 */     if (isNull1) {
/* 047 */       rowWriter.setNullAt(1);
/* 048 */     } else {
/* 049 */       // Remember the current cursor so that we can calculate how many bytes are
/* 050 */       // written later.
/* 051 */       final int tmpCursor1 = holder.cursor;
/* 052 */
/* 053 */       if (value1 instanceof UnsafeArrayData) {
/* 054 */
/* 055 */         final int sizeInBytes = ((UnsafeArrayData) value1).getSizeInBytes();
/* 056 */         // grow the global buffer before writing data.
/* 057 */         holder.grow(sizeInBytes);
/* 058 */         ((UnsafeArrayData) value1).writeToMemory(holder.buffer, holder.cursor);
/* 059 */         holder.cursor += sizeInBytes;
/* 060 */
/* 061 */       } else {
/* 062 */         final int numElements = value1.numElements();
/* 063 */         arrayWriter.initialize(holder, numElements, 0);
/* 064 */
/* 065 */         for (int index = 0; index < numElements; index++) {
/* 066 */           if (value1.isNullAt(index)) {
/* 067 */             arrayWriter.setNullAt(index);
/* 068 */           } else {
/* 069 */             final UTF8String element = value1.getUTF8String(index);
/* 070 */             arrayWriter.write(index, element);
/* 071 */           }
/* 072 */         }
/* 073 */       }
/* 074 */
/* 075 */       rowWriter.setOffsetAndSize(1, tmpCursor1, holder.cursor - tmpCursor1);
/* 076 */       rowWriter.alignToWords(holder.cursor - tmpCursor1);
/* 077 */     }
/* 078 */
/* 079 */
/* 080 */     boolean isNull2 = i.isNullAt(2);
/* 081 */     ArrayData value2 = isNull2 ? null : (i.getArray(2));
/* 082 */     if (isNull2) {
/* 083 */       rowWriter.setNullAt(2);
/* 084 */     } else {
/* 085 */       // Remember the current cursor so that we can calculate how many bytes are
/* 086 */       // written later.
/* 087 */       final int tmpCursor2 = holder.cursor;
/* 088 */
/* 089 */       if (value2 instanceof UnsafeArrayData) {
/* 090 */
/* 091 */         final int sizeInBytes1 = ((UnsafeArrayData) value2).getSizeInBytes();
/* 092 */         // grow the global buffer before writing data.
/* 093 */         holder.grow(sizeInBytes1);
/* 094 */         ((UnsafeArrayData) value2).writeToMemory(holder.buffer, holder.cursor);
/* 095 */         holder.cursor += sizeInBytes1;
/* 096 */
/* 097 */       } else {
/* 098 */         final int numElements1 = value2.numElements();
/* 099 */         arrayWriter1.initialize(holder, numElements1, 0);
/* 100 */
/* 101 */         for (int index1 = 0; index1 < numElements1; index1++) {
/* 102 */           if (value2.isNullAt(index1)) {
/* 103 */             arrayWriter1.setNullAt(index1);
/* 104 */           } else {
/* 105 */             final UTF8String element1 = value2.getUTF8String(index1);
/* 106 */             arrayWriter1.write(index1, element1);
/* 107 */           }
/* 108 */         }
/* 109 */       }
/* 110 */
/* 111 */       rowWriter.setOffsetAndSize(2, tmpCursor2, holder.cursor - tmpCursor2);
/* 112 */       rowWriter.alignToWords(holder.cursor - tmpCursor2);
/* 113 */     }
/* 114 */     result.setTotalSize(holder.totalSize());
/* 115 */     return result;
/* 116 */   }
/* 117 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.485422 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(0);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 0);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 0);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */
/* 027 */     return result;
/* 028 */   }
/* 029 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private UnsafeRow result;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder holder;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter rowWriter;
/* 011 */
/* 012 */
/* 013 */   public SpecificUnsafeProjection(Object[] references) {
/* 014 */     this.references = references;
/* 015 */     result = new UnsafeRow(0);
/* 016 */     this.holder = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(result, 0);
/* 017 */     this.rowWriter = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(holder, 0);
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */
/* 027 */     return result;
/* 028 */   }
/* 029 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.847597 ms
DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection - code for input[0, string, true],input[1, string, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (MutableRow) references[references.length - 1];
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public java.lang.Object apply(java.lang.Object _i) {
/* 019 */     InternalRow i = (InternalRow) _i;
/* 020 */
/* 021 */     boolean isNull = i.isNullAt(0);
/* 022 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 023 */     if (isNull) {
/* 024 */       mutableRow.setNullAt(0);
/* 025 */     } else {
/* 026 */
/* 027 */       mutableRow.update(0, value.clone().clone());
/* 028 */     }
/* 029 */
/* 030 */     boolean isNull1 = i.isNullAt(1);
/* 031 */     UTF8String value1 = isNull1 ? null : (i.getUTF8String(1));
/* 032 */     if (isNull1) {
/* 033 */       mutableRow.setNullAt(1);
/* 034 */     } else {
/* 035 */
/* 036 */       mutableRow.update(1, value1.clone().clone());
/* 037 */     }
/* 038 */
/* 039 */     boolean isNull2 = i.isNullAt(2);
/* 040 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 041 */     if (isNull2) {
/* 042 */       mutableRow.setNullAt(2);
/* 043 */     } else {
/* 044 */
/* 045 */       mutableRow.update(2, value2.clone().clone());
/* 046 */     }
/* 047 */
/* 048 */     return mutableRow;
/* 049 */   }
/* 050 */ }

DEBUG Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */
/* 010 */
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (MutableRow) references[references.length - 1];
/* 015 */
/* 016 */   }
/* 017 */
/* 018 */   public java.lang.Object apply(java.lang.Object _i) {
/* 019 */     InternalRow i = (InternalRow) _i;
/* 020 */
/* 021 */     boolean isNull = i.isNullAt(0);
/* 022 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 023 */     if (isNull) {
/* 024 */       mutableRow.setNullAt(0);
/* 025 */     } else {
/* 026 */
/* 027 */       mutableRow.update(0, value.clone().clone());
/* 028 */     }
/* 029 */
/* 030 */     boolean isNull1 = i.isNullAt(1);
/* 031 */     UTF8String value1 = isNull1 ? null : (i.getUTF8String(1));
/* 032 */     if (isNull1) {
/* 033 */       mutableRow.setNullAt(1);
/* 034 */     } else {
/* 035 */
/* 036 */       mutableRow.update(1, value1.clone().clone());
/* 037 */     }
/* 038 */
/* 039 */     boolean isNull2 = i.isNullAt(2);
/* 040 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 041 */     if (isNull2) {
/* 042 */       mutableRow.setNullAt(2);
/* 043 */     } else {
/* 044 */
/* 045 */       mutableRow.update(2, value2.clone().clone());
/* 046 */     }
/* 047 */
/* 048 */     return mutableRow;
/* 049 */   }
/* 050 */ }

INFO Executor task launch worker-0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.625105 ms
DEBUG Executor task launch worker-0 org.apache.spark.memory.TaskMemoryManager - Task 4 release 16.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@345355e9
DEBUG Executor task launch worker-0 org.apache.spark.memory.TaskMemoryManager - Task 4 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@345355e9
INFO Executor task launch worker-0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 4). 9632 bytes result sent to driver
DEBUG dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_3, runningTasks: 0
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 4) in 1005 ms on localhost (1/1)
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (show at PQDataMLLib.scala:30) finished in 1.006 s
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - After removal of stage 2, remaining stages = 1
DEBUG dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - After removal of stage 3, remaining stages = 0
INFO main org.apache.spark.scheduler.DAGScheduler - Job 2 finished: show at PQDataMLLib.scala:30, took 3.635369 s
DEBUG main org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection - code for createexternalrow(input[0, string, true].toString, staticinvoke(class scala.collection.mutable.WrappedArray$, ObjectType(interface scala.collection.Seq), make, mapobjects(MapObjects_loopValue12, MapObjects_loopIsNull13, StringType, lambdavariable(MapObjects_loopValue12, MapObjects_loopIsNull13, StringType).toString, input[1, array<string>, true]).array, true), staticinvoke(class scala.collection.mutable.WrappedArray$, ObjectType(interface scala.collection.Seq), make, mapobjects(MapObjects_loopValue14, MapObjects_loopIsNull15, StringType, lambdavariable(MapObjects_loopValue14, MapObjects_loopIsNull15, StringType).toString, input[2, array<string>, true]).array, true), StructField(quote_id,StringType,true), StructField(PR2,ArrayType(StringType,true),true), StructField(PR1,ArrayType(StringType,true),true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private boolean MapObjects_loopIsNull13;
/* 011 */   private UTF8String MapObjects_loopValue12;
/* 012 */   private boolean MapObjects_loopIsNull15;
/* 013 */   private UTF8String MapObjects_loopValue14;
/* 014 */   private org.apache.spark.sql.types.StructType schema;
/* 015 */
/* 016 */
/* 017 */   public SpecificSafeProjection(Object[] references) {
/* 018 */     this.references = references;
/* 019 */     mutableRow = (MutableRow) references[references.length - 1];
/* 020 */
/* 021 */
/* 022 */
/* 023 */
/* 024 */
/* 025 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */     values = new Object[3];
/* 032 */
/* 033 */     boolean isNull2 = i.isNullAt(0);
/* 034 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 035 */
/* 036 */     boolean isNull1 = isNull2;
/* 037 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 038 */     isNull1 = value1 == null;
/* 039 */     if (isNull1) {
/* 040 */       values[0] = null;
/* 041 */     } else {
/* 042 */       values[0] = value1;
/* 043 */     }
/* 044 */
/* 045 */     boolean isNull6 = i.isNullAt(1);
/* 046 */     ArrayData value6 = isNull6 ? null : (i.getArray(1));
/* 047 */     ArrayData value5 = null;
/* 048 */
/* 049 */     if (!isNull6) {
/* 050 */
/* 051 */       java.lang.String[] convertedArray = null;
/* 052 */       int dataLength = value6.numElements();
/* 053 */       convertedArray = new java.lang.String[dataLength];
/* 054 */
/* 055 */       int loopIndex = 0;
/* 056 */       while (loopIndex < dataLength) {
/* 057 */         MapObjects_loopValue12 = (UTF8String) (value6.getUTF8String(loopIndex));
/* 058 */         MapObjects_loopIsNull13 = value6.isNullAt(loopIndex);
/* 059 */
/* 060 */
/* 061 */         boolean isNull7 = MapObjects_loopIsNull13;
/* 062 */         final java.lang.String value7 = isNull7 ? null : (java.lang.String) MapObjects_loopValue12.toString();
/* 063 */         isNull7 = value7 == null;
/* 064 */         if (isNull7) {
/* 065 */           convertedArray[loopIndex] = null;
/* 066 */         } else {
/* 067 */           convertedArray[loopIndex] = value7;
/* 068 */         }
/* 069 */
/* 070 */         loopIndex += 1;
/* 071 */       }
/* 072 */
/* 073 */       value5 = new org.apache.spark.sql.catalyst.util.GenericArrayData(convertedArray);
/* 074 */     }
/* 075 */
/* 076 */     boolean isNull4 = isNull6;
/* 077 */     final java.lang.Object value4 = isNull4 ? null : (java.lang.Object) value5.array();
/* 078 */     isNull4 = value4 == null;
/* 079 */     boolean isNull3 = isNull4;
/* 080 */     final scala.collection.Seq value3 = isNull3 ? null : scala.collection.mutable.WrappedArray.make(value4);
/* 081 */     isNull3 = value3 == null;
/* 082 */     if (isNull3) {
/* 083 */       values[1] = null;
/* 084 */     } else {
/* 085 */       values[1] = value3;
/* 086 */     }
/* 087 */
/* 088 */     boolean isNull11 = i.isNullAt(2);
/* 089 */     ArrayData value11 = isNull11 ? null : (i.getArray(2));
/* 090 */     ArrayData value10 = null;
/* 091 */
/* 092 */     if (!isNull11) {
/* 093 */
/* 094 */       java.lang.String[] convertedArray1 = null;
/* 095 */       int dataLength1 = value11.numElements();
/* 096 */       convertedArray1 = new java.lang.String[dataLength1];
/* 097 */
/* 098 */       int loopIndex1 = 0;
/* 099 */       while (loopIndex1 < dataLength1) {
/* 100 */         MapObjects_loopValue14 = (UTF8String) (value11.getUTF8String(loopIndex1));
/* 101 */         MapObjects_loopIsNull15 = value11.isNullAt(loopIndex1);
/* 102 */
/* 103 */
/* 104 */         boolean isNull12 = MapObjects_loopIsNull15;
/* 105 */         final java.lang.String value12 = isNull12 ? null : (java.lang.String) MapObjects_loopValue14.toString();
/* 106 */         isNull12 = value12 == null;
/* 107 */         if (isNull12) {
/* 108 */           convertedArray1[loopIndex1] = null;
/* 109 */         } else {
/* 110 */           convertedArray1[loopIndex1] = value12;
/* 111 */         }
/* 112 */
/* 113 */         loopIndex1 += 1;
/* 114 */       }
/* 115 */
/* 116 */       value10 = new org.apache.spark.sql.catalyst.util.GenericArrayData(convertedArray1);
/* 117 */     }
/* 118 */
/* 119 */     boolean isNull9 = isNull11;
/* 120 */     final java.lang.Object value9 = isNull9 ? null : (java.lang.Object) value10.array();
/* 121 */     isNull9 = value9 == null;
/* 122 */     boolean isNull8 = isNull9;
/* 123 */     final scala.collection.Seq value8 = isNull8 ? null : scala.collection.mutable.WrappedArray.make(value9);
/* 124 */     isNull8 = value8 == null;
/* 125 */     if (isNull8) {
/* 126 */       values[2] = null;
/* 127 */     } else {
/* 128 */       values[2] = value8;
/* 129 */     }
/* 130 */
/* 131 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 132 */     if (false) {
/* 133 */       mutableRow.setNullAt(0);
/* 134 */     } else {
/* 135 */
/* 136 */       mutableRow.update(0, value);
/* 137 */     }
/* 138 */
/* 139 */     return mutableRow;
/* 140 */   }
/* 141 */ }

DEBUG main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private MutableRow mutableRow;
/* 009 */   private Object[] values;
/* 010 */   private boolean MapObjects_loopIsNull13;
/* 011 */   private UTF8String MapObjects_loopValue12;
/* 012 */   private boolean MapObjects_loopIsNull15;
/* 013 */   private UTF8String MapObjects_loopValue14;
/* 014 */   private org.apache.spark.sql.types.StructType schema;
/* 015 */
/* 016 */
/* 017 */   public SpecificSafeProjection(Object[] references) {
/* 018 */     this.references = references;
/* 019 */     mutableRow = (MutableRow) references[references.length - 1];
/* 020 */
/* 021 */
/* 022 */
/* 023 */
/* 024 */
/* 025 */     this.schema = (org.apache.spark.sql.types.StructType) references[0];
/* 026 */   }
/* 027 */
/* 028 */   public java.lang.Object apply(java.lang.Object _i) {
/* 029 */     InternalRow i = (InternalRow) _i;
/* 030 */
/* 031 */     values = new Object[3];
/* 032 */
/* 033 */     boolean isNull2 = i.isNullAt(0);
/* 034 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 035 */
/* 036 */     boolean isNull1 = isNull2;
/* 037 */     final java.lang.String value1 = isNull1 ? null : (java.lang.String) value2.toString();
/* 038 */     isNull1 = value1 == null;
/* 039 */     if (isNull1) {
/* 040 */       values[0] = null;
/* 041 */     } else {
/* 042 */       values[0] = value1;
/* 043 */     }
/* 044 */
/* 045 */     boolean isNull6 = i.isNullAt(1);
/* 046 */     ArrayData value6 = isNull6 ? null : (i.getArray(1));
/* 047 */     ArrayData value5 = null;
/* 048 */
/* 049 */     if (!isNull6) {
/* 050 */
/* 051 */       java.lang.String[] convertedArray = null;
/* 052 */       int dataLength = value6.numElements();
/* 053 */       convertedArray = new java.lang.String[dataLength];
/* 054 */
/* 055 */       int loopIndex = 0;
/* 056 */       while (loopIndex < dataLength) {
/* 057 */         MapObjects_loopValue12 = (UTF8String) (value6.getUTF8String(loopIndex));
/* 058 */         MapObjects_loopIsNull13 = value6.isNullAt(loopIndex);
/* 059 */
/* 060 */
/* 061 */         boolean isNull7 = MapObjects_loopIsNull13;
/* 062 */         final java.lang.String value7 = isNull7 ? null : (java.lang.String) MapObjects_loopValue12.toString();
/* 063 */         isNull7 = value7 == null;
/* 064 */         if (isNull7) {
/* 065 */           convertedArray[loopIndex] = null;
/* 066 */         } else {
/* 067 */           convertedArray[loopIndex] = value7;
/* 068 */         }
/* 069 */
/* 070 */         loopIndex += 1;
/* 071 */       }
/* 072 */
/* 073 */       value5 = new org.apache.spark.sql.catalyst.util.GenericArrayData(convertedArray);
/* 074 */     }
/* 075 */
/* 076 */     boolean isNull4 = isNull6;
/* 077 */     final java.lang.Object value4 = isNull4 ? null : (java.lang.Object) value5.array();
/* 078 */     isNull4 = value4 == null;
/* 079 */     boolean isNull3 = isNull4;
/* 080 */     final scala.collection.Seq value3 = isNull3 ? null : scala.collection.mutable.WrappedArray.make(value4);
/* 081 */     isNull3 = value3 == null;
/* 082 */     if (isNull3) {
/* 083 */       values[1] = null;
/* 084 */     } else {
/* 085 */       values[1] = value3;
/* 086 */     }
/* 087 */
/* 088 */     boolean isNull11 = i.isNullAt(2);
/* 089 */     ArrayData value11 = isNull11 ? null : (i.getArray(2));
/* 090 */     ArrayData value10 = null;
/* 091 */
/* 092 */     if (!isNull11) {
/* 093 */
/* 094 */       java.lang.String[] convertedArray1 = null;
/* 095 */       int dataLength1 = value11.numElements();
/* 096 */       convertedArray1 = new java.lang.String[dataLength1];
/* 097 */
/* 098 */       int loopIndex1 = 0;
/* 099 */       while (loopIndex1 < dataLength1) {
/* 100 */         MapObjects_loopValue14 = (UTF8String) (value11.getUTF8String(loopIndex1));
/* 101 */         MapObjects_loopIsNull15 = value11.isNullAt(loopIndex1);
/* 102 */
/* 103 */
/* 104 */         boolean isNull12 = MapObjects_loopIsNull15;
/* 105 */         final java.lang.String value12 = isNull12 ? null : (java.lang.String) MapObjects_loopValue14.toString();
/* 106 */         isNull12 = value12 == null;
/* 107 */         if (isNull12) {
/* 108 */           convertedArray1[loopIndex1] = null;
/* 109 */         } else {
/* 110 */           convertedArray1[loopIndex1] = value12;
/* 111 */         }
/* 112 */
/* 113 */         loopIndex1 += 1;
/* 114 */       }
/* 115 */
/* 116 */       value10 = new org.apache.spark.sql.catalyst.util.GenericArrayData(convertedArray1);
/* 117 */     }
/* 118 */
/* 119 */     boolean isNull9 = isNull11;
/* 120 */     final java.lang.Object value9 = isNull9 ? null : (java.lang.Object) value10.array();
/* 121 */     isNull9 = value9 == null;
/* 122 */     boolean isNull8 = isNull9;
/* 123 */     final scala.collection.Seq value8 = isNull8 ? null : scala.collection.mutable.WrappedArray.make(value9);
/* 124 */     isNull8 = value8 == null;
/* 125 */     if (isNull8) {
/* 126 */       values[2] = null;
/* 127 */     } else {
/* 128 */       values[2] = value8;
/* 129 */     }
/* 130 */
/* 131 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, schema);
/* 132 */     if (false) {
/* 133 */       mutableRow.setNullAt(0);
/* 134 */     } else {
/* 135 */
/* 136 */       mutableRow.update(0, value);
/* 137 */     }
/* 138 */
/* 139 */     return mutableRow;
/* 140 */   }
/* 141 */ }

INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.31127 ms
INFO Thread-1 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.server.Server@431cd9b2
DEBUG Thread-1 org.spark_project.jetty.server.Server - Graceful shutdown org.spark_project.jetty.server.Server@431cd9b2 by 
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping ServerConnector@4f0f2942{HTTP/1.1}{0.0.0.0:4040}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@387a8303
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.io.SelectorManager$ManagedSelector@9cb8225 keys=0 selected=0
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Stopping org.spark_project.jetty.io.SelectorManager$ManagedSelector@9cb8225 keys=0 selected=0
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Queued change org.spark_project.jetty.io.SelectorManager$ManagedSelector$Stop@40082cfc
DEBUG SparkUI-34-selector-ServerConnectorManager@387a8303/0 org.spark_project.jetty.io.SelectorManager - Selector loop woken up from select, 0/0 selected
DEBUG SparkUI-34-selector-ServerConnectorManager@387a8303/0 org.spark_project.jetty.io.SelectorManager - Running change org.spark_project.jetty.io.SelectorManager$ManagedSelector$Stop@40082cfc
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Stopped org.spark_project.jetty.io.SelectorManager$ManagedSelector@9cb8225 keys=-1 selected=-1
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.io.SelectorManager$ManagedSelector@9cb8225 keys=-1 selected=-1
DEBUG SparkUI-34-selector-ServerConnectorManager@387a8303/0 org.spark_project.jetty.io.SelectorManager - Stopped Thread[SparkUI-34-selector-ServerConnectorManager@387a8303/0,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@9cb8225 keys=-1 selected=-1
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.io.SelectorManager$ManagedSelector@376a0d86 keys=0 selected=0
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Stopping org.spark_project.jetty.io.SelectorManager$ManagedSelector@376a0d86 keys=0 selected=0
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Queued change org.spark_project.jetty.io.SelectorManager$ManagedSelector$Stop@5367e46d
DEBUG SparkUI-35-selector-ServerConnectorManager@387a8303/1 org.spark_project.jetty.io.SelectorManager - Selector loop woken up from select, 0/0 selected
DEBUG SparkUI-35-selector-ServerConnectorManager@387a8303/1 org.spark_project.jetty.io.SelectorManager - Running change org.spark_project.jetty.io.SelectorManager$ManagedSelector$Stop@5367e46d
DEBUG Thread-1 org.spark_project.jetty.io.SelectorManager - Stopped org.spark_project.jetty.io.SelectorManager$ManagedSelector@376a0d86 keys=-1 selected=-1
DEBUG SparkUI-35-selector-ServerConnectorManager@387a8303/1 org.spark_project.jetty.io.SelectorManager - Stopped Thread[SparkUI-35-selector-ServerConnectorManager@387a8303/1,5,main] on org.spark_project.jetty.io.SelectorManager$ManagedSelector@376a0d86 keys=-1 selected=-1
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.io.SelectorManager$ManagedSelector@376a0d86 keys=-1 selected=-1
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@387a8303
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping HttpConnectionFactory@34bde49d{HTTP/1.1}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED HttpConnectionFactory@34bde49d{HTTP/1.1}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@20b2475a
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@20b2475a
INFO Thread-1 org.spark_project.jetty.server.ServerConnector - Stopped ServerConnector@4f0f2942{HTTP/1.1}{0.0.0.0:4040}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED ServerConnector@4f0f2942{HTTP/1.1}{0.0.0.0:4040}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.server.Server@431cd9b2
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@57db2b13[org.spark_project.jetty.servlets.gzip.GzipHandler@7e057f43, org.spark_project.jetty.servlets.gzip.GzipHandler@31ea9581, org.spark_project.jetty.servlets.gzip.GzipHandler@7d9d0818, org.spark_project.jetty.servlets.gzip.GzipHandler@4d1c005e, org.spark_project.jetty.servlets.gzip.GzipHandler@70ed52de, org.spark_project.jetty.servlets.gzip.GzipHandler@6be968ce, org.spark_project.jetty.servlets.gzip.GzipHandler@303cf2ba, org.spark_project.jetty.servlets.gzip.GzipHandler@609e8838, org.spark_project.jetty.servlets.gzip.GzipHandler@792b749c, org.spark_project.jetty.servlets.gzip.GzipHandler@514646ef, org.spark_project.jetty.servlets.gzip.GzipHandler@7ae0a9ec, org.spark_project.jetty.servlets.gzip.GzipHandler@1040be71, org.spark_project.jetty.servlets.gzip.GzipHandler@3f4faf53, org.spark_project.jetty.servlets.gzip.GzipHandler@723ca036, org.spark_project.jetty.servlets.gzip.GzipHandler@52f27fbd, org.spark_project.jetty.servlets.gzip.GzipHandler@c430e6c, org.spark_project.jetty.servlets.gzip.GzipHandler@66982506, org.spark_project.jetty.servlets.gzip.GzipHandler@6c4906d3, org.spark_project.jetty.servlets.gzip.GzipHandler@6b695b06, org.spark_project.jetty.servlets.gzip.GzipHandler@7d900ecf, org.spark_project.jetty.servlets.gzip.GzipHandler@673fdbce, org.spark_project.jetty.servlets.gzip.GzipHandler@5b799640, org.spark_project.jetty.servlets.gzip.GzipHandler@2ab4bc72, org.spark_project.jetty.servlets.gzip.GzipHandler@7bd7d6d6, o.s.j.s.ServletContextHandler@5d12a356{/metrics/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@663411de{/SQL,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@75cd8043{/SQL/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@4535b6d5{/SQL/execution,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@232a7d73{/SQL/execution/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@7f36662c{/static/sql,null,SHUTDOWN}]
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@57db2b13[org.spark_project.jetty.servlets.gzip.GzipHandler@7e057f43, org.spark_project.jetty.servlets.gzip.GzipHandler@31ea9581, org.spark_project.jetty.servlets.gzip.GzipHandler@7d9d0818, org.spark_project.jetty.servlets.gzip.GzipHandler@4d1c005e, org.spark_project.jetty.servlets.gzip.GzipHandler@70ed52de, org.spark_project.jetty.servlets.gzip.GzipHandler@6be968ce, org.spark_project.jetty.servlets.gzip.GzipHandler@303cf2ba, org.spark_project.jetty.servlets.gzip.GzipHandler@609e8838, org.spark_project.jetty.servlets.gzip.GzipHandler@792b749c, org.spark_project.jetty.servlets.gzip.GzipHandler@514646ef, org.spark_project.jetty.servlets.gzip.GzipHandler@7ae0a9ec, org.spark_project.jetty.servlets.gzip.GzipHandler@1040be71, org.spark_project.jetty.servlets.gzip.GzipHandler@3f4faf53, org.spark_project.jetty.servlets.gzip.GzipHandler@723ca036, org.spark_project.jetty.servlets.gzip.GzipHandler@52f27fbd, org.spark_project.jetty.servlets.gzip.GzipHandler@c430e6c, org.spark_project.jetty.servlets.gzip.GzipHandler@66982506, org.spark_project.jetty.servlets.gzip.GzipHandler@6c4906d3, org.spark_project.jetty.servlets.gzip.GzipHandler@6b695b06, org.spark_project.jetty.servlets.gzip.GzipHandler@7d900ecf, org.spark_project.jetty.servlets.gzip.GzipHandler@673fdbce, org.spark_project.jetty.servlets.gzip.GzipHandler@5b799640, org.spark_project.jetty.servlets.gzip.GzipHandler@2ab4bc72, org.spark_project.jetty.servlets.gzip.GzipHandler@7bd7d6d6, o.s.j.s.ServletContextHandler@5d12a356{/metrics/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@663411de{/SQL,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@75cd8043{/SQL/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@4535b6d5{/SQL/execution,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@232a7d73{/SQL/execution/json,null,SHUTDOWN}, o.s.j.s.ServletContextHandler@7f36662c{/static/sql,null,SHUTDOWN}]
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7bd7d6d6
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7bd7d6d6
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@33065d67{/stages/stage/kill,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@33065d67{/stages/stage/kill,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@712625fd
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@712625fd
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$3-7bba5817@bf1c457f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$3-7bba5817@bf1c457f==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@712625fd
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@33065d67{/stages/stage/kill,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@33065d67{/stages/stage/kill,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@7bd7d6d6
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@2ab4bc72
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@2ab4bc72
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@3b0fe47a{/api,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@3b0fe47a{/api,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@202b0582
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@202b0582
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4b8729ff@500abb78==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-4b8729ff@500abb78==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,-1,false
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.glassfish.jersey.servlet.ServletContainer-4be29ed9@e20fd74a==org.glassfish.jersey.servlet.ServletContainer,-1,false
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.glassfish.jersey.servlet.ServletContainer-4be29ed9@e20fd74a==org.glassfish.jersey.servlet.ServletContainer,-1,false
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@202b0582
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3b0fe47a{/api,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@3b0fe47a{/api,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@2ab4bc72
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@5b799640
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@5b799640
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@543295b0{/,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@543295b0{/,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@54422e18
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@54422e18
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$3-117159c0@e3bf1fb7==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$3-117159c0@e3bf1fb7==org.apache.spark.ui.JettyUtils$$anon$3,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@54422e18
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@543295b0{/,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@543295b0{/,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@5b799640
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@673fdbce
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@673fdbce
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@2a265ea9{/static,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@2a265ea9{/static,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@11392934
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@11392934
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.DefaultServlet-793f29ff@91a8bbcb==org.spark_project.jetty.servlet.DefaultServlet,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.DefaultServlet-793f29ff@91a8bbcb==org.spark_project.jetty.servlet.DefaultServlet,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@11392934
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2a265ea9{/static,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@2a265ea9{/static,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@673fdbce
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7d900ecf
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7d900ecf
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@7526515b{/executors/threadDump/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@7526515b{/executors/threadDump/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@1ed4ae0f
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@1ed4ae0f
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-54c5a2ff@790e93cf==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-54c5a2ff@790e93cf==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@1ed4ae0f
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7526515b{/executors/threadDump/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@7526515b{/executors/threadDump/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@7d900ecf
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6b695b06
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6b695b06
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@26d9b808{/executors/threadDump,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@26d9b808{/executors/threadDump,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@f78a47e
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@f78a47e
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-644baf4a@9336da4b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-644baf4a@9336da4b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@f78a47e
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@26d9b808{/executors/threadDump,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@26d9b808{/executors/threadDump,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@6b695b06
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6c4906d3
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6c4906d3
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@2a7f1f10{/executors/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@2a7f1f10{/executors/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@46cdf8bd
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@46cdf8bd
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-f0c8a99@b1cc2e35==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-f0c8a99@b1cc2e35==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@46cdf8bd
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2a7f1f10{/executors/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@2a7f1f10{/executors/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@6c4906d3
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@66982506
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@66982506
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@2e385cce{/executors,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@2e385cce{/executors,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@2ddc9a9f
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@2ddc9a9f
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-298a5e20@2e2958b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-298a5e20@2e2958b==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@2ddc9a9f
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2e385cce{/executors,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@2e385cce{/executors,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@66982506
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@c430e6c
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@c430e6c
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@63376bed{/environment/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@63376bed{/environment/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@4145bad8
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@4145bad8
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-d86a6f@f22b4d7c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-d86a6f@f22b4d7c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@4145bad8
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@63376bed{/environment/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@63376bed{/environment/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@c430e6c
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@52f27fbd
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@52f27fbd
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@71ba6d4e{/environment,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@71ba6d4e{/environment,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@738dc9b
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@738dc9b
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-3c77d488@14996d8d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-3c77d488@14996d8d==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@738dc9b
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@71ba6d4e{/environment,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@71ba6d4e{/environment,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@52f27fbd
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@723ca036
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@723ca036
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@20140db9{/storage/rdd/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@20140db9{/storage/rdd/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@1e6a3214
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@1e6a3214
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-368247b9@c979a4c4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-368247b9@c979a4c4==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@1e6a3214
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@20140db9{/storage/rdd/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@20140db9{/storage/rdd/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@723ca036
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@3f4faf53
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@3f4faf53
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@6c1a5b54{/storage/rdd,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@6c1a5b54{/storage/rdd,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@1c7696c6
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@1c7696c6
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-60099951@b675ef4c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-60099951@b675ef4c==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@1c7696c6
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6c1a5b54{/storage/rdd,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@6c1a5b54{/storage/rdd,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@3f4faf53
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@1040be71
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@1040be71
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@45099dd3{/storage/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@45099dd3{/storage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@13e344d
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@13e344d
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-1ffaf86@1a8497a7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-1ffaf86@1a8497a7==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@13e344d
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@45099dd3{/storage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@45099dd3{/storage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@1040be71
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7ae0a9ec
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@7ae0a9ec
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@41a0aa7d{/storage,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@41a0aa7d{/storage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@2794eab6
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@2794eab6
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-6340e5f0@5b912740==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-6340e5f0@5b912740==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@2794eab6
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@41a0aa7d{/storage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@41a0aa7d{/storage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@7ae0a9ec
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@514646ef
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@514646ef
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@229c6181{/stages/pool/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@229c6181{/stages/pool/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@4686afc2
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@4686afc2
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-1e0b4072@a4f9afaa==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-1e0b4072@a4f9afaa==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@4686afc2
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@229c6181{/stages/pool/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@229c6181{/stages/pool/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@514646ef
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@792b749c
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@792b749c
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@18df8434{/stages/pool,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@18df8434{/stages/pool,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@65c7a252
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@65c7a252
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-4d154ccd@a6f276f1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-4d154ccd@a6f276f1==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@65c7a252
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@18df8434{/stages/pool,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@18df8434{/stages/pool,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@792b749c
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@609e8838
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@609e8838
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@7b36aa0c{/stages/stage/json,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@7b36aa0c{/stages/stage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@5824a83d
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@5824a83d
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-537f60bf@fbb208f8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-537f60bf@fbb208f8==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@5824a83d
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7b36aa0c{/stages/stage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@7b36aa0c{/stages/stage/json,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@609e8838
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@303cf2ba
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@303cf2ba
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping o.s.j.s.ServletContextHandler@3012646b{/stages/stage,null,SHUTDOWN}
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping o.s.j.s.ServletContextHandler@3012646b{/stages/stage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlet.ServletHandler@4a883b15
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlet.ServletHandler@4a883b15
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.apache.spark.ui.JettyUtils$$anon$2-25641d39@29640087==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.apache.spark.ui.JettyUtils$$anon$2-25641d39@29640087==org.apache.spark.ui.JettyUtils$$anon$2,-1,true
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlet.ServletHandler@4a883b15
INFO Thread-1 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3012646b{/stages/stage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED o.s.j.s.ServletContextHandler@3012646b{/stages/stage,null,UNAVAILABLE}
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - STOPPED org.spark_project.jetty.servlets.gzip.GzipHandler@303cf2ba
DEBUG Thread-1 org.spark_project.jetty.util.component.AbstractLifeCycle - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6be968ce
DEBUG Thread-1 org.spark_project.jetty.server.handler.AbstractHandler - stopping org.spark_project.jetty.servlets.gzip.GzipHandler@6be968ce
